{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "def generate_weighted_adjacency_matrix():\n",
    "    print(\"生成带权邻接矩阵 A...\")\n",
    "    # 构建随机图结构\n",
    "    G = nx.grid_2d_graph(10, 10)\n",
    "    A = np.zeros((100, 100))\n",
    "    for (i, j) in G.edges():\n",
    "        weight = np.random.uniform(2, 5)\n",
    "        A[i,j] = weight\n",
    "        A[j,i] = weight\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成底层精度矩阵 Theta\n",
    "def generate_precision_matrix(A):\n",
    "    delta = 1.05 * np.max(np.linalg.eigvals(A))\n",
    "    Theta = delta * np.eye(100) - A\n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Theta(A):\n",
    "    def find_E(A):\n",
    "        diag_tmp = np.diag(A)\n",
    "        E = np.diag(1 / np.sqrt(diag_tmp))\n",
    "        return E\n",
    "    tmp = np.linalg.inv(A)\n",
    "    E = find_E(tmp)\n",
    "    E = np.linalg.inv(E)\n",
    "    Theta = E @ A @ E\n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成观测数据\n",
    "def generate_observation_data(Theta, n):\n",
    "    Theta_star = get_Theta(Theta)\n",
    "    Theta_star_inv = np.linalg.inv(Theta_star)\n",
    "    mean = np.zeros(100)\n",
    "    samples = np.random.multivariate_normal(mean, Theta_star_inv, size=n)\n",
    "    cov_matrix = np.cov(samples, rowvar=False)\n",
    "    return samples, cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义权重更新函数 p_lambda (使用SCAD penalty)\n",
    "def p_lambda(x):\n",
    "    a = 3.7\n",
    "    threshold = 0.8 * a\n",
    "    return np.where(x <= threshold, a * x,  a/2 * (np.abs(x) - threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def objective_function(Theta, bSigma, lambda_func):\n",
    "    n = Theta.shape[0]\n",
    "    log_det = -np.log(np.linalg.det(Theta))\n",
    "    trace_term = np.trace(Theta @ bSigma)\n",
    "    penalty_term = np.sum(lambda_func * (Theta - np.diag(np.diag(Theta))))\n",
    "    #print(log_det + trace_term - penalty_term)\n",
    "    return log_det + trace_term - penalty_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度计算\n",
    "def compute_gradient(Theta, bSigma, lambda_func):\n",
    "    gradient = -np.linalg.inv(Theta) + bSigma - lambda_func\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_matrix(X):\n",
    "    projection = np.zeros_like(X)\n",
    "    rows, cols = X.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if i == j:\n",
    "                projection[i,j] = X[i,j]\n",
    "            else:\n",
    "                projection[i,j] = min(0, X[i,j])\n",
    "    return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_M_matrix(A):\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        return False\n",
    "    for i in range(A.shape[0]):\n",
    "        if A[i,i] > 0:\n",
    "            return False\n",
    "        for j in range(A.shape[1]):\n",
    "            if i != j and A[i,j] < 0:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_gradient_projection(Theta, bSigma, lambda_func, sigma, alpha, beta):\n",
    "    # while True:\n",
    "    for i in range(100):\n",
    "        gradient = compute_gradient(Theta, bSigma, lambda_func)\n",
    "        m = 0\n",
    "        while True:\n",
    "            tmp_matrix = Theta - sigma * (beta ** m) * gradient\n",
    "            #print(\"Theta: \", Theta)\n",
    "            Theta_new = projection_matrix(tmp_matrix)\n",
    "            #print(\"Theta_new: \", Theta_new)\n",
    "            # m += 1\n",
    "            factor = 1 / sigma / (beta ** m) * (Theta - Theta_new)\n",
    "            if np.all(np.linalg.eigvals(Theta_new) > 0) and \\\n",
    "                    objective_function(Theta_new, bSigma, lambda_func) <= \\\n",
    "                    objective_function(Theta, bSigma, lambda_func) - \\\n",
    "                    alpha * sigma * (beta ** m) * np.linalg.norm(factor, 'fro') ** 2:\n",
    "                Theta = Theta_new\n",
    "                break\n",
    "            m += 1\n",
    "        Theta = Theta_new\n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = generate_weighted_adjacency_matrix()\n",
    "Theta = generate_precision_matrix(A)\n",
    "samples, bSigma = generate_observation_data(Theta, 100)\n",
    "#print(bSigma)\n",
    "print(Theta)\n",
    "\n",
    "prev_Theta = np.identity(100)\n",
    "sigma = 0.05\n",
    "alpha = 0.003\n",
    "beta = 0.5\n",
    "\n",
    "for k in range(10):\n",
    "    lambda_func = p_lambda(np.abs(Theta - np.diag(np.diag(Theta))))\n",
    "    #print(\"lambda: \", lambda_func)\n",
    "    Theta_new1 = perform_gradient_projection(Theta, bSigma, lambda_func, sigma, alpha, beta)\n",
    "    #print(Theta_new1)\n",
    "    Theta = Theta_new1\n",
    "\n",
    "#print(Theta_new1)\n",
    "\n",
    "Theta_tmp = generate_precision_matrix(A)\n",
    "theta_star = get_Theta(Theta_tmp)\n",
    "estimation_error = np.linalg.norm(Theta_new1 - theta_star, 'fro') / np.linalg.norm(theta_star, 'fro')\n",
    "print(estimation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_evaluation_metrics(Theta_hat, Theta_star, threshold=0.1):\n",
    "    # 二值化估计的和真实的精度矩阵\n",
    "    estimated_binary = (np.abs(Theta_hat) > threshold).astype(int)\n",
    "    true_binary = (np.abs(Theta_star) > threshold).astype(int)\n",
    "\n",
    "    # 计算真正例（TP）、假正例（FP）、真负例（TN）和假负例（FN）\n",
    "    TP = np.sum(np.logical_and(estimated_binary == 1, true_binary == 1))\n",
    "    FP = np.sum(np.logical_and(estimated_binary == 1, true_binary == 0))\n",
    "    TN = np.sum(np.logical_and(estimated_binary == 0, true_binary == 0))\n",
    "    FN = np.sum(np.logical_and(estimated_binary == 0, true_binary == 1))\n",
    "\n",
    "    # 计算真正例率（TPR）、假正例率（FPR）和 F-score\n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "    F_score = 2 * TP / (2 * TP + FP + FN)\n",
    "\n",
    "    return TPR, FPR, F_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sltp_precision(samples, alpha = 0.5):\n",
    "    cov_estimator = GraphicalLassoCV()\n",
    "    cov_estimator.fit(samples)\n",
    "    cov_matrix = cov_estimator.covariance_\n",
    "    n_samples = samples.shape[0]\n",
    "    L, lower = cho_factor(cov_matrix)\n",
    "    sltp_matrix = cho_solve((L, lower), np.eye(n_samples)) / alpha\n",
    "    return sltp_matrix\n",
    "\n",
    "Theta_SLTP = sltp_precision(samples)\n",
    "Theta_GLasso = GraphicalLassoCV().fit(samples).precision_\n",
    "TPR, FPR, F_score = calculate_evaluation_metrics(Theta_SLTP, theta_star)\n",
    "estimation_error = np.linalg.norm(Theta_SLTP - theta_star, 'fro') / np.linalg.norm(theta_star, 'fro')\n",
    "print(\"SLTP Method\")\n",
    "print(\"error:\", estimation_error)\n",
    "print(\"TPR:\", TPR)\n",
    "print(\"FPR:\", FPR)\n",
    "print(\"F-score:\", F_score)\n",
    "print('\\n')\n",
    "TPR_g, FPR_g, F_score_g = calculate_evaluation_metrics(Theta_GLasso, theta_star)\n",
    "estimation_error_g = np.linalg.norm(Theta_GLasso - theta_star, 'fro') / np.linalg.norm(theta_star, 'fro')\n",
    "print(\"GLasso Method\")\n",
    "print(\"error:\", estimation_error_g)\n",
    "print(\"TPR:\", TPR_g)\n",
    "print(\"FPR:\", FPR_g)\n",
    "print(\"F-score:\", F_score_g)\n",
    "TPR_p, FPR_p, F_score_p = calculate_evaluation_metrics(Theta_new1, theta_star)\n",
    "estimation_error_p = np.linalg.norm(Theta_new1 - theta_star, 'fro') / np.linalg.norm(theta_star, 'fro')\n",
    "print(\"Proposed Method\")\n",
    "print(\"error:\", estimation_error_p)\n",
    "print(\"TPR:\", TPR_p)\n",
    "print(\"FPR:\", FPR_p)\n",
    "print(\"F-score:\", F_score_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建一个10x10的grid网络\n",
    "grid_graph = nx.grid_2d_graph(10, 10)\n",
    "\n",
    "# 创建一个line网络\n",
    "line_graph = nx.path_graph(100)\n",
    "\n",
    "# 创建一个Barabasi-Albert模型网络\n",
    "barabasi_albert_graph = nx.barabasi_albert_graph(100, 1)\n",
    "\n",
    "# 创建一个Stochastic Block Model网络\n",
    "n = 100\n",
    "p = [[0.1, 0.02, 0.02, 0.02],  # 第一个块内连接概率\n",
    "     [0.02, 0.1, 0.02, 0.02],  # 第二个块内连接概率\n",
    "     [0.02, 0.02, 0.1, 0.02],  # 第三个块内连接概率\n",
    "     [0.02, 0.02, 0.02, 0.1]]  # 第四个块内连接概率\n",
    "\n",
    "block_sizes = [n // 4, n // 4, n // 4, n // 4]  # 四个块的节点数量\n",
    "\n",
    "sbm_graph = nx.stochastic_block_model(block_sizes, p, seed=0)\n",
    "\n",
    "# 创建一个2x2的图\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# 绘制Grid Network\n",
    "plt.subplot(2, 2, 1)\n",
    "pos = nx.spring_layout(grid_graph)\n",
    "nx.draw(grid_graph, pos, with_labels=False, node_size=50, node_color='skyblue', edge_color='gray', linewidths=0.5)\n",
    "plt.title(\"Grid Network\")\n",
    "\n",
    "# 绘制Line Network\n",
    "plt.subplot(2, 2, 2)\n",
    "pos = nx.spring_layout(line_graph)\n",
    "nx.draw(line_graph, pos, with_labels=False, node_size=50, node_color='lightgreen', edge_color='gray', linewidths=0.5)\n",
    "plt.title(\"Line Network\")\n",
    "\n",
    "# 绘制Barabasi-Albert Network\n",
    "plt.subplot(2, 2, 3)\n",
    "pos = nx.spring_layout(barabasi_albert_graph)\n",
    "nx.draw(barabasi_albert_graph, pos, with_labels=False, node_size=50, node_color='lightcoral', edge_color='gray', linewidths=0.5)\n",
    "plt.title(\"Barabasi-Albert Network\")\n",
    "\n",
    "# 绘制Stochastic Block Model Network\n",
    "plt.subplot(2, 2, 4)\n",
    "pos = nx.spring_layout(sbm_graph)\n",
    "nx.draw(sbm_graph, pos, with_labels=False, node_size=50, node_color='lightblue', edge_color='gray', linewidths=0.5)\n",
    "plt.title(\"Stochastic Block Model Network\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_line_adjacency_matrix():\n",
    "    print(\"生成带权邻接矩阵 A...\")\n",
    "    # 构建随机图结构\n",
    "    G = nx.path_graph(100)\n",
    "    A = np.zeros((100, 100))\n",
    "    for (i, j) in G.edges():\n",
    "        weight = np.random.uniform(2, 5)\n",
    "        A[i,j] = weight\n",
    "        A[j,i] = weight\n",
    "    \n",
    "    return A\n",
    "\n",
    "A_line = generate_line_adjacency_matrix()\n",
    "Theta_line = generate_precision_matrix(A_line)\n",
    "samples_line, bSigma_line = generate_observation_data(Theta_line, 40)\n",
    "\n",
    "prev_Theta = np.identity(100)\n",
    "sigma = 0.05\n",
    "alpha = 0.01\n",
    "beta = 0.5\n",
    "\n",
    "for k in range(10):\n",
    "    lambda_func_line = p_lambda(np.abs(Theta_line - np.diag(np.diag(Theta_line))))\n",
    "    #print(\"lambda: \", lambda_func)\n",
    "    Theta_new1_line = perform_gradient_projection(Theta_line, bSigma_line, lambda_func_line, sigma, alpha, beta)\n",
    "    #print(Theta_new1)\n",
    "    Theta_line = Theta_new1_line\n",
    "\n",
    "Theta_tmp_line = generate_precision_matrix(A_line)\n",
    "theta_star_line = get_Theta(Theta_tmp_line)\n",
    "estimation_error_line = np.linalg.norm(Theta_new1_line - theta_star_line, 'fro') / np.linalg.norm(theta_star_line, 'fro')\n",
    "print(estimation_error_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_barabasi_adjacency_matrix():\n",
    "    print(\"生成带权邻接矩阵 A...\")\n",
    "    # 构建随机图结构\n",
    "    G = nx.barabasi_albert_graph(100, 1)\n",
    "    A = np.zeros((100, 100))\n",
    "    for (i, j) in G.edges():\n",
    "        weight = np.random.uniform(2, 5)\n",
    "        A[i,j] = weight\n",
    "        A[j,i] = weight\n",
    "    \n",
    "    return A\n",
    "\n",
    "A_barabasi = generate_barabasi_adjacency_matrix()\n",
    "Theta_barabasi = generate_precision_matrix(A_barabasi)\n",
    "samples_barabasi, bSigma_barabasi = generate_observation_data(Theta_barabasi, 100)\n",
    "\n",
    "prev_Theta = np.identity(100)\n",
    "sigma = 0.05\n",
    "alpha = 0.01\n",
    "beta = 0.5\n",
    "\n",
    "for k in range(10):\n",
    "    lambda_func_barabasi = p_lambda(np.abs(Theta_barabasi - np.diag(np.diag(Theta_barabasi))))\n",
    "    #print(\"lambda: \", lambda_func)\n",
    "    Theta_new1_barabasi = perform_gradient_projection(Theta_barabasi, bSigma_barabasi, lambda_func_barabasi, sigma, alpha, beta)\n",
    "    #print(Theta_new1)\n",
    "    Theta_barabasi = Theta_new1_barabasi\n",
    "\n",
    "Theta_tmp_barabasi = generate_precision_matrix(A_barabasi)\n",
    "theta_star_barabasi = get_Theta(Theta_tmp_barabasi)\n",
    "estimation_error_barabasi = np.linalg.norm(Theta_new1_barabasi - theta_star_barabasi, 'fro') / np.linalg.norm(theta_star_barabasi, 'fro')\n",
    "print(estimation_error_barabasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stock_adjacency_matrix():\n",
    "    print(\"生成带权邻接矩阵 A...\")\n",
    "    # 构建随机图结构\n",
    "    G = sbm_graph\n",
    "    A = np.zeros((100, 100))\n",
    "    for (i, j) in G.edges():\n",
    "        weight = np.random.uniform(2, 5)\n",
    "        A[i,j] = weight\n",
    "        A[j,i] = weight\n",
    "    \n",
    "    return A\n",
    "\n",
    "A_stock = generate_stock_adjacency_matrix()\n",
    "Theta_stock = generate_precision_matrix(A_stock)\n",
    "samples_stock, bSigma_stock = generate_observation_data(Theta_stock, 100)\n",
    "\n",
    "prev_Theta = np.identity(100)\n",
    "sigma = 0.05\n",
    "alpha = 0.01\n",
    "beta = 0.5\n",
    "\n",
    "for k in range(10):\n",
    "    lambda_func_stock = p_lambda(np.abs(Theta_stock - np.diag(np.diag(Theta_stock))))\n",
    "    Theta_new1_stock = perform_gradient_projection(Theta_stock, bSigma_stock, lambda_func_stock, sigma, alpha, beta)\n",
    "    #print(Theta_new1)\n",
    "    Theta_stock = Theta_new1_stock\n",
    "\n",
    "Theta_tmp_stock = generate_precision_matrix(A_stock)\n",
    "theta_star_stock = get_Theta(Theta_tmp_stock)\n",
    "estimation_error_stock = np.linalg.norm(Theta_new1_stock - theta_star_stock, 'fro') / np.linalg.norm(theta_star_stock, 'fro')\n",
    "print(estimation_error_stock)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3196968d684371006099b3d55edeef8ed90365227a30deaef86e5d4aa8519be0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
